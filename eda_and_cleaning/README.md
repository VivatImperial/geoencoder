# EDA и очистка датасета адресов

Анализ и отсев странных/неполных адресов перед обучением геокодера.

## Запуск

Из корня репозитория:

```bash
uv run python eda_and_cleaning/analyze_addresses.py --csv data/addresses_spb.csv --out-dir eda_and_cleaning
```

Опции: `--out-dir`, `--cleaned-csv` (имя файла очищенного CSV в каталоге).

## Результаты

- **report.md** — текстовый отчёт: количество отсеянных, причины, примеры.
- **summary.json** — сводка и примеры по каждой причине отсева.
- **addresses_spb_cleaned.csv** — очищенный датасет (только адреса, прошедшие правила).
- **dropped_examples.json** — примеры отсеянных записей с указанием причины.

## Правила отсева (geocoding.cleaning)

| Причина | Описание |
|--------|----------|
| `too_short` | Длина адреса < 5 символов |
| `number_range_only` | Только цифры, дефисы, точки с запятой (диапазоны квартир и т.п.) |
| `invalid_placeholder` | Содержит fixme, todo, unknown и т.п. |
| `ru_only_or_ru_plus_one` | Первая часть — «RU», частей не больше двух (страна или страна + город/регион без улицы) |
| `ru_postcode_only` | Формат «RU, 123456» |
| `no_digit` | Нет ни одной цифры (нет номера дома) |

## Пайплайн

При загрузке CSV в обучении (`geocoding.data.load_csv`) эти же правила применяются автоматически: неполные адреса не попадают в train/val/test. Очищенный CSV можно использовать напрямую (`--csv eda_and_cleaning/addresses_spb_cleaned.csv`), тогда фильтр при загрузке ничего дополнительно не отсеет.
